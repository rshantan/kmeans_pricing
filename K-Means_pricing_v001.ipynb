{
 "metadata": {
  "name": "",
  "signature": "sha256:2328e6badf204b0eb7db7ac80fe625fac0684509303511bec68518b8a9346bdf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Kmeans Pricing Tool\n",
      "DRAFT\n",
      "Q1 2016 \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "import psycopg2\n",
      "from sqlalchemy import create_engine\n",
      "import numpy as np\n",
      "import csv\n",
      "import boto\n",
      "import time\n",
      "\n",
      "\"\"\" Config \"\"\"\n",
      "REDSHIFTUSER = ''\n",
      "REDSHIFTPWD = ''\n",
      "AWSKEY= '' \n",
      "AWSSECRETKEY= ''\n",
      "SCHEMA = ''\n",
      "DATABASE = ''\n",
      "HOST = ''\n",
      "BUCKET = ''\n",
      "PROJECT = '' \n",
      "KEYNAME = ''\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create call to set Default Schema"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function to connect to DB and extract data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class PricingModel(object):\n",
      "\n",
      "    def __init__(self):\n",
      "        \"\"\" Connect to the database and fetch the Product Details.\n",
      "        Two different libraries are used to connect to redshift. sqlalchemy is used for its integration with pandas\n",
      "        while psycopg2 is used to write the results to the db.\n",
      "        \"\"\"\n",
      "        self.conn = psycopg2.connect(\n",
      "            , \n",
      "            host=HOST,\n",
      "            user=REDSHIFTUSER, \n",
      "            port=5439, \n",
      "            password=REDSHIFTPWD,\n",
      "            database=DATABASE)\n",
      "        self.cur = self.conn.cursor() # create a cursor for executing queries\n",
      "\n",
      "        engine_string = \"postgresql+psycopg2://%s:%s@%s:%d/%s\" \\\n",
      "            % (REDSHIFTUSER, REDSHIFTPWD, HOST, 5439, DATABASE)\n",
      "        self.engine = create_engine(engine_string)\n",
      "\n",
      "        query_string = \"select * from vw_product_details;\"\n",
      "        self.df = pd.read_sql_query(query_string, self.engine)\n",
      "\n",
      "        q_string = \"\"\"select split_part(orderlinesku, '-', 1) as sku , orderlineqty, orderdate, totalorderlinegrossvalue, orderlinepromotioncodes, orderlineid, bhline.orderid\n",
      "into temp_table\n",
      "from vw_order_line  bhline \n",
      "join vw_order_header  bhheader \n",
      "on bhline.orderid=bhheader.orderid;\"\"\"\n",
      "        q_string2 = \"\"\"select sku, sum(orderlineqty) number_orders, \n",
      "sum(totalorderlinegrossvalue) as total_cost,\n",
      "pgdate_part('week', orderdate) as week, \n",
      "pgdate_part('year', orderdate) as year \n",
      "into temp_table3\n",
      "from temp_table2\n",
      "group by 1, 4, 5;\"\"\"\n",
      "        q_string3 = \"\"\"select * into temp_table2 from temp_table tt LEFT JOIN bh_returnheader ret ON ret.ordernumber = tt.orderid WHERE ret.ordernumber IS NULL;\n",
      "        \"\"\"\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table2;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table3;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "        self.cur.execute(q_string)\n",
      "        self.conn.commit()\n",
      "        self.cur.execute(q_string3)\n",
      "        self.conn.commit()\n",
      "        self.cur.execute(q_string2)\n",
      "        self.conn.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clustering function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    def cluster(self):\n",
      "        \"\"\" Perform clustering on the textual features describing the items of clothing.\n",
      "        \"\"\"\n",
      "        df = self.df.fillna('') #  change all nans to empty strings\n",
      "        # add all of the text features together\n",
      "        text_features = df['name'] + ' ' + df['product_group'] + ' ' + \\\n",
      "                        df['category'] + ' ' + df['department'] + ' ' + \\\n",
      "                        df['length'] + ' ' + df['origin'] + ' ' + \\\n",
      "                        df['style'] + ' ' + df['neckline'] + ' ' + \\\n",
      "                        df['trend'] + ' ' + df['heelshape'] + ' ' + \\\n",
      "                        df['toe'] + ' ' + df['sole'] + ' ' + \\\n",
      "                        df['heelheight'] + ' ' + df['wash'] + ' ' + \\\n",
      "                        df['enduse']\n",
      "\n",
      "        numerical_features = df[['cost_price', 'weight']]\n",
      "\n",
      "        tf = TfidfVectorizer(min_df=2)\n",
      "        self.X = tf.fit_transform(text_features)\n",
      "\n",
      "        self.nbrs = NearestNeighbors()\n",
      "        self.nbrs.fit(self.X)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pricing Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    def calculate_prices(self):\n",
      "\n",
      "        with open('boohoo-pricing.csv', 'wb') as csvfile:\n",
      "            self.spamwriter = csv.writer(csvfile)\n",
      "\n",
      "            for index, row in self.df.iterrows():\n",
      "                # [(k, v.sku) for k,v in self.df.iterrows() if v.sku == 'DZZ90335']\n",
      "                res = self.nbrs.kneighbors(self.X[index], return_distance=False)\n",
      "                similar_skus = tuple([self.df.sku[a] for a in res[0]])\n",
      "\n",
      "                query_string = \"select * from  temp_table3 where sku  in ('{0}','{1}','{2}','{3}','{4}')\".format(similar_skus[0], similar_skus[1], similar_skus[2], similar_skus[3], similar_skus[4]);\n",
      "\n",
      "                res_df = pd.read_sql_query(query_string, self.engine)\n",
      "\n",
      "                sku = self.df['sku'][index]\n",
      "                try:\n",
      "                    ideal_price = sum(res_df['total_cost'])/sum(res_df['number_orders'])\n",
      "                except:\n",
      "                    ideal_price = self.df['cost_price'][index] + 10\n",
      "\n",
      "                cost_price = self.df['cost_price'][index]\n",
      "                total_weeks = len(res_df.groupby(['week', 'year']).count())\n",
      "                self.name = self.df['name'][index]\n",
      "                self.department = self.df['product_group'][index]\n",
      "                sp = res_df[res_df['sku'] == sku]\n",
      "                try:\n",
      "                    sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
      "                except:\n",
      "                    sim_items_sold_per_week = 10\n",
      "                try:\n",
      "                    items_sold_per_week = sum(sp['number_orders'])/len(sp)\n",
      "                except:\n",
      "                    items_sold_per_week = sim_items_sold_per_week \n",
      "                try:\n",
      "                    self.sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
      "                except:\n",
      "                    self.sim_items_sold_per_week = 10\n",
      "                new_price = (ideal_price/sim_items_sold_per_week)*items_sold_per_week\n",
      "\n",
      "                weeks_on_sale = res_df[res_df['sku'] == sku].count()['sku']\n",
      "                \n",
      "                published = self.df['published'][index]\n",
      "                in_clearance = self.df['in_clearance'][index]\n",
      "                act_weeks_on_sale = self.df['act_weeks_on_sale'][index]\n",
      "                original_standard_price = self.df['original_standard_price'][index]\n",
      "                current_standard_price = self.df['current_standard_price'][index]\n",
      "                        \n",
      "                self.current_price = current_standard_price\n",
      "                q_string = \"\"\"select totalorderlinegrossvalue from temp_table2 where orderlineid = (select max(orderlineid) from  temp_table where sku = '{}' and orderlinepromotioncodes = '')\"\"\".format(sku)\n",
      "                actual_df = pd.read_sql_query(q_string, self.engine)\n",
      "                try:\n",
      "                    self.actual_price = actual_df['totalorderlinegrossvalue'].loc[0]\n",
      "                except:\n",
      "                    self.actual_price = 0\n",
      "\n",
      "                try:\n",
      "                    ss = res_df[res_df['sku'] == sku].loc[0]\n",
      "                    self.current_price = ss['total_cost']/ss['number_orders']\n",
      "                except Exception as e: \n",
      "                    self.current_price = self.actual_price\n",
      "                if self.current_price == 0:\n",
      "                    self.current_price = current_standard_price \n",
      "\n",
      "                min_price = 0\n",
      "                if act_weeks_on_sale < 5:\n",
      "                    min_price = self.price_point(self.df['product_group'][index].upper(), self.current_price)\n",
      "                if min_price > new_price:\n",
      "                    new_price = min_price\n",
      "\n",
      "                if new_price > (original_standard_price + original_standard_price/10):\n",
      "                    new_price = (original_standard_price + original_standard_price/10)\n",
      "\n",
      "                                   \n",
      "                self.calculate_clearance_price(sku, items_sold_per_week, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculates the clearance price"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    def calculate_clearance_price(self, sku, items_sold_per_week, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price):\n",
      "        query_string = \"\"\"SELECT si.ItemID,Code,Price,sip.PriceBandId,pb.Name, bi.quantityonhand, si.manufacturer\n",
      "FROM bh_StockItem si\n",
      "join bh_StockItemPrice sip on si.ItemID = sip.ItemID\n",
      "join bh_PriceBand pb on pb.PriceBandID = sip.PriceBandID\n",
      "join bh_dwh_stock_levels bi on si.code = bi.productid\n",
      "where pb.Name = 'Offer Price' and split_part(Code, '-', 1) = '{0}'\"\"\".format(sku)\n",
      "\n",
      "    res_df_cl = pd.read_sql_query(query_string, self.engine) ## query string??\n",
      "    try:\n",
      "        price = res_df_cl['price'].loc[0]\n",
      "    except: \n",
      "        price = 0\n",
      "    clearance_price = price\n",
      "    output_list = {}\n",
      "    predicted_throughput = self.sim_items_sold_per_week \n",
      "    stock_level = sum(res_df_cl['confirmedqtyinstock'])\n",
      "    try:\n",
      "        weeks_of_stock = stock_level/items_sold_per_week\n",
      "    except: \n",
      "        weeks_of_stock = 0\n",
      "    current_velocity = items_sold_per_week ## What's the purpose of this??\n",
      "    current_margin = self.current_price - cost_price\n",
      "    for weeks in [2,4,6,8,10]:\n",
      "        if stock_level < (weeks*items_sold_per_week):\n",
      "            clearance_price = new_price\n",
      "            tp = predicted_throughput \n",
      "        else:\n",
      "            try:\n",
      "                clearance_price = new_price*(items_sold_per_week/(stock_level/weeks))\n",
      "                tp = (predicted_throughput - predicted_throughput * (items_sold_per_week/(stock_level/weeks))) + predicted_throughput \n",
      "            except: \n",
      "                clearance_price = new_price\n",
      "                tp = predicted_throughput \n",
      "\n",
      "        if clearance_price < cost_price:\n",
      "            clearance_price = cost_price\n",
      "        if new_price < price:\n",
      "            new_price = price                   \n",
      "        output_list[\"week{0}\".format(weeks)] = clearance_price\n",
      "        output_list[\"margin{0}\".format(weeks)] = clearance_price - cost_price\n",
      "        output_list[\"tp\".format(weeks)] = tp\n",
      "        output_list[\"cd{0}\".format(weeks)] = (clearance_price - self.current_price)*stock_level\n",
      "        \n",
      "    cost_decision = (new_price - self.current_price)*stock_level\n",
      "    predicted_margin = new_price - cost_price\n",
      "    other_outputvars = dict(sku = sku, new_price = new_price, current_price = self.current_price, actual_price = self.actual_price,weeks_of_stock = weeks_of_stock ,current_velocity = current_velocity,current_margin = current_margin,predicted_throughput = predicted_throughput,predicted_margin = predicted_margin, stock_level = stock_level, name = self.name, department = self.department,cost_decision = cost_decision)\n",
      "    output_list.update(other_outputvars)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    def price_point(self, group, current_price):\n",
      "        query = \"\"\"select * from price_architecture where sub_group = '{0}' order by price\"\"\".format(group)\n",
      "        price_points = pd.read_sql_query(query, self.engine)\n",
      "        prices = price_points['price']\n",
      "        try:\n",
      "            idx = np.where((np.abs(prices.tolist())-current_price)==((np.abs(prices.tolist())-current_price).argmin()))[0][0]\n",
      "        except:\n",
      "            return 0\n",
      "        idx = idx - 2\n",
      "        if idx < 0:\n",
      "            idx = 0\n",
      "        return price_points['price'][idx]\n",
      "\n",
      "\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " def write_to_db(self):\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table2;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "        try:\n",
      "            self.cur.execute(\"drop table temp_table3;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "\n",
      "        s3 = boto.connect_s3(AWSKEY, AWSSECRETKEY)\n",
      "        bucket = s3.get_bucket(BUCKET)\n",
      "        key_name =  '%s%s' % (PROJECT,int(time.time()))\n",
      "        print(key_name)\n",
      "        key = bucket.new_key(key_name)\n",
      "        key.set_contents_from_filename('%s.csv' %(PROJECT))\n",
      "        try:\n",
      "            self.cur.execute(\"drop table pricing_latest;\")\n",
      "            self.conn.commit()\n",
      "        except:\n",
      "            self.conn.commit()\n",
      "            pass\n",
      "\n",
      "        self.cur.execute(\"create table pricing_latest (sku varchar,optimal_price float,week2_price float , week4_price float, week6_price float, suggested_price float, week10_price float, current_price float, weeks_of_stock float, Current_weekly_velocity float, current_margin float, predicted_throughput float, predicted_margin float, stock_level float, name varchar, department varchar, week2_margin float, week4_margin float, week6_margin float, week8_margin float, week10_margin float, predicted_throughput_was_relevant_to_2_weeks float, predicted_throughput_was_relevant_to_4_weeks float, predicted_throughput_was_relevant_to_6_weeks float, predicted_throughput_was_relevant_to_8_weeks float, predicted_throughput_was_relevant_to_10_weeks float, cost_of_the_decision_was_relevant_to_2_weeks float, cost_of_the_decision_was_relevant_to_4_weeks float,cost_of_the_decision_was_relevant_to_6_weeks float, cost_of_the_decision_was_relevant_to_8_weeks float, cost_of_the_decision_was_relevant_to_10_weeks float, cost_of_the_decision float, parent_group varchar, season varchar, cost_price float, published varchar, in_clearance varchar, act_weeks_on_sale float, original_standard_price float, current_standard_price float, current_percentage_achieved_margin float, suggested_price_percentage_margin float, suggestion varchar,price_2_Weeks_Percentage_Margin float, price_4_Weeks_Percentage_Margin float, price_6_Weeks_Percentage_Margin float, price_8_Weeks_Percentage_Margin float, price_10_Weeks_Percentage_Margin float, demand_Pounds_Last_7_Days float, next_7_days_weekly_velocity float,demand_pounds_next_7_days float,next_7_days_margin float,stock_level_next_7_days float, currentdate timestamp default '2016-10-01 00:00:00.0');\")\n",
      "\n",
      "                                                                                                                                                                                                                                                                                            \n",
      "        self.conn.commit()\n",
      "        self.cur.execute(\"copy pricing_latest from 's3://%s/%s' CSV credentials 'aws_access_key_id=%s;aws_secret_access_key=%s';\" % (BUCKET,key_name, AWSKEY, AWSSECRETKEY))\n",
      "        self.conn.commit()\n",
      "\n",
      "pm = PricingModel()\n",
      "pm.cluster()\n",
      "pm.calculate_prices()\n",
      "pm.write_to_db()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}