{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans Pricing Tool\n",
    "DRAFT\n",
    "Q1 2016 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import csv\n",
    "import boto\n",
    "import time\n",
    "\n",
    "\"\"\" Config \"\"\"\n",
    "REDSHIFTUSER = ''\n",
    "REDSHIFTPWD = ''\n",
    "AWSKEY= '' \n",
    "AWSSECRETKEY= ''\n",
    "SCHEMA = ''\n",
    "DATABASE = ''\n",
    "HOST = ''\n",
    "BUCKET = ''\n",
    "PROJECT = '' \n",
    "KEYNAME = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create call to set Default Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to connect to DB and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PricingModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Connect to the database and fetch the Product Details.\n",
    "        Two different libraries are used to connect to redshift. sqlalchemy is used for its integration with pandas\n",
    "        while psycopg2 is used to write the results to the db.\n",
    "        \"\"\"\n",
    "        self.conn = psycopg2.connect(\n",
    "            , \n",
    "            host=HOST,\n",
    "            user=REDSHIFTUSER, \n",
    "            port=5439, \n",
    "            password=REDSHIFTPWD,\n",
    "            database=DATABASE)\n",
    "        self.cur = self.conn.cursor() # create a cursor for executing queries\n",
    "\n",
    "        engine_string = \"postgresql+psycopg2://%s:%s@%s:%d/%s\" \\\n",
    "            % (REDSHIFTUSER, REDSHIFTPWD, HOST, 5439, DATABASE)\n",
    "        self.engine = create_engine(engine_string)\n",
    "\n",
    "        query_string = \"select * from vw_product_details;\"\n",
    "        self.df = pd.read_sql_query(query_string, self.engine)\n",
    "\n",
    "        ## Changed the queries to eliminate the trycatch statements, changed the froup by clause in string 3 and made csmetics changes\n",
    "        q_string = \"\"\"DROP TABLE IF EXISTS temp_table1;\n",
    "                        select split_part(orderlinesku, '-', 1) as sku , orderlineqty, orderdate, totalorderlinegrossvalue,orderlinepromotioncodes, orderlineid, bhline.orderid\n",
    "                        into temp_table\n",
    "                        from vw_order_line  bhline \n",
    "                        join vw_order_header  bhheader \n",
    "                        on bhline.orderid=bhheader.orderid;\"\"\"\n",
    "        \n",
    "        q_string2 = \"\"\"DROP TABLE IF EXISTS temp_table2;\n",
    "                        select * \n",
    "                        into temp_table2 \n",
    "                        from temp_table tt \n",
    "                        LEFT JOIN bh_returnheader ret \n",
    "                        ON ret.ordernumber = tt.orderid \n",
    "                        WHERE ret.ordernumber IS NULL;\"\"\"\n",
    "        q_string3 = \"\"\"DROP TABLE IF EXISTS temp_table3;\n",
    "                        select sku, sum(orderlineqty) number_orders, \n",
    "                        sum(totalorderlinegrossvalue) as total_cost,\n",
    "                        pgdate_part('week', orderdate) as week, \n",
    "                        pgdate_part('year', orderdate) as year \n",
    "                        into temp_table3\n",
    "                        from temp_table2\n",
    "                        group by sku,pgdate_part('week', orderdate),pgdate_part('year', orderdate);\"\"\"\n",
    "        \n",
    "        self.cur.execute(q_string)\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(q_string2)\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(q_string3)\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster(self):\n",
    "    \"\"\" Perform clustering on the textual features describing the items of clothing.\n",
    "    \"\"\"\n",
    "    df = self.df.fillna('') #  change all nans to empty strings\n",
    "    # add all of the text features together\n",
    "    text_features = df['name'] + ' ' + df['product_group'] + ' ' + \\\n",
    "                    df['category'] + ' ' + df['department'] + ' ' + \\\n",
    "                    df['length'] + ' ' + df['origin'] + ' ' + \\\n",
    "                    df['style'] + ' ' + df['neckline'] + ' ' + \\\n",
    "                    df['trend'] + ' ' + df['heelshape'] + ' ' + \\\n",
    "                    df['toe'] + ' ' + df['sole'] + ' ' + \\\n",
    "                    df['heelheight'] + ' ' + df['wash'] + ' ' + \\\n",
    "                    df['enduse']\n",
    "\n",
    "    numerical_features = df[['cost_price', 'weight']]\n",
    "\n",
    "    tf = TfidfVectorizer(min_df=2)\n",
    "    self.X = tf.fit_transform(text_features)\n",
    "\n",
    "    self.nbrs = NearestNeighbors()\n",
    "    self.nbrs.fit(self.X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pricing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_prices(self):\n",
    "## Added comments, made the code readable. Also changed the order of variable creation for readability\n",
    "    # res_df_cl_all is only used to be passed as as an argument in the calculate_clearance_price function.\n",
    "    # Intialized it here in order to avoid multiple calls to the DB. Not related to the other res_df in the fn.\n",
    "    query_string = \"\"\"SELECT si.ItemID,Code,Price,sip.PriceBandId,pb.Name, bi.quantityonhand, si.manufacturer\n",
    "                        FROM bh_StockItem si\n",
    "                        join bh_StockItemPrice sip on si.ItemID = sip.ItemID\n",
    "                        join bh_PriceBand pb on pb.PriceBandID = sip.PriceBandID\n",
    "                        join bh_dwh_stock_levels bi on si.code = bi.productid\n",
    "                        where pb.Name = 'Offer Price'\"\"\"\"\n",
    "\n",
    "    res_df_cl_all = pd.read_sql_query(query_string, self.engine) \n",
    "\n",
    "    with open('boohoo-pricing.csv', 'wb') as csvfile:\n",
    "        self.spamwriter = csv.writer(csvfile)\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            # [(k, v.sku) for k,v in self.df.iterrows() if v.sku == 'DZZ90335']\n",
    "            ## Initialize Values\n",
    "            published = self.df['published'][index]\n",
    "            in_clearance = self.df['in_clearance'][index]\n",
    "            act_weeks_on_sale = self.df['act_weeks_on_sale'][index]\n",
    "            original_standard_price = self.df['original_standard_price'][index]\n",
    "            current_standard_price = self.df['current_standard_price'][index]\n",
    "            cost_price = self.df['cost_price'][index]\n",
    "            sku = self.df['sku'][index]\n",
    "\n",
    "            self.name = self.df['name'][index]\n",
    "            self.department = self.df['product_group'][index]\n",
    "            self.current_price = current_standard_price ## Why are we doing this??\n",
    "\n",
    "            # Find Similar Skus\n",
    "            res = self.nbrs.kneighbors(self.X[index], return_distance=False)\n",
    "            similar_skus = tuple([self.df.sku[a] for a in res[0]])\n",
    "\n",
    "            # Get orders of similar skus, summarized by week\n",
    "            query_string = \"select * from  temp_table3 where sku  in ('{0}','{1}','{2}','{3}','{4}')\".format(similar_skus[0], similar_skus[1], similar_skus[2], similar_skus[3], similar_skus[4]);\n",
    "            res_df = pd.read_sql_query(query_string, self.engine)               \n",
    "\n",
    "            total_weeks = len(res_df.groupby(['week', 'year']).count())\n",
    "            # Calculate some values of Similar skus\n",
    "            try:\n",
    "                ideal_price = sum(res_df['total_cost'])/sum(res_df['number_orders'])\n",
    "            except:\n",
    "                ideal_price = self.df['cost_price'][index] + 10\n",
    "            ## merged the try except statements\n",
    "            try:\n",
    "                sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
    "                self.sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
    "            except:\n",
    "                sim_items_sold_per_week = 10 \n",
    "                self.sim_items_sold_per_week = 10\n",
    "\n",
    "            # Calculate values of actual sku\n",
    "            sp = res_df[res_df['sku'] == sku]\n",
    "            try:\n",
    "                items_sold_per_week = sum(sp['number_orders'])/len(sp)\n",
    "            except:\n",
    "                items_sold_per_week = sim_items_sold_per_week \n",
    "\n",
    "            #implement pricing logic\n",
    "            new_price = (ideal_price/sim_items_sold_per_week)*items_sold_per_week\n",
    "            weeks_on_sale = sp.count()['sku']\n",
    "\n",
    "            q_string = \"\"\"select totalorderlinegrossvalue from temp_table2 where orderlineid = (select max(orderlineid) from  temp_table where sku = '{}' and orderlinepromotioncodes = '')\"\"\".format(sku)\n",
    "            actual_df = pd.read_sql_query(q_string, self.engine)\n",
    "\n",
    "            try:\n",
    "                self.actual_price = actual_df['totalorderlinegrossvalue'].loc[0] \n",
    "            except:\n",
    "                self.actual_price = 0\n",
    "\n",
    "            try:\n",
    "                ss = sp.loc[0]\n",
    "                self.current_price = ss['total_cost']/ss['number_orders'] # practically, is this different from actual price?\n",
    "            except Exception as e: \n",
    "                self.current_price = self.actual_price\n",
    "            if self.current_price == 0:\n",
    "                self.current_price = current_standard_price \n",
    "\n",
    "            # Introduce some rule based checks\n",
    "            min_price = 0\n",
    "            if act_weeks_on_sale < 5:\n",
    "                min_price = self.price_point(self.df['product_group'][index].upper(), self.current_price)\n",
    "\n",
    "            if new_price < min_price:\n",
    "                new_price = min_price\n",
    "            if new_price > (original_standard_price + original_standard_price/10):\n",
    "                new_price = (original_standard_price + original_standard_price/10)\n",
    "\n",
    "            res_df_cl = res_df_cl_all[res_df_cl_all['sku']==sku]    # to pass to the function below\n",
    "            self.calculate_clearance_price(sku, res_df_cl, items_sold_per_week, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price)\n",
    "            ## Ideal price need not be passed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the clearance price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_clearance_price(self, sku, res_df_cl, items_sold_per_week, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price):\n",
    "    ## Ideal price is not used\n",
    "    try:\n",
    "        price = res_df_cl['price'].loc[0]\n",
    "    except: \n",
    "        price = 0\n",
    "    clearance_price = price\n",
    "    output_list = {}\n",
    "    predicted_throughput = self.sim_items_sold_per_week \n",
    "    stock_level = sum(res_df_cl['confirmedqtyinstock'])\n",
    "    try:\n",
    "        weeks_of_stock = stock_level/items_sold_per_week\n",
    "    except: \n",
    "        weeks_of_stock = 0\n",
    "    current_velocity = items_sold_per_week ## What's the purpose of this?? Can be removed\n",
    "    current_margin = self.current_price - cost_price\n",
    "    for weeks in [2,4,6,8,10]:\n",
    "        if stock_level < (weeks*items_sold_per_week):\n",
    "            clearance_price = new_price\n",
    "            tp = predicted_throughput \n",
    "        else:\n",
    "            try:\n",
    "                clearance_price = new_price*(items_sold_per_week/(stock_level/weeks))\n",
    "                tp = (predicted_throughput - predicted_throughput * (items_sold_per_week/(stock_level/weeks))) + predicted_throughput \n",
    "            except: \n",
    "                clearance_price = new_price\n",
    "                tp = predicted_throughput \n",
    "\n",
    "        if clearance_price < cost_price:\n",
    "            clearance_price = cost_price\n",
    "        if new_price < price:\n",
    "            new_price = price                   \n",
    "        output_list[\"week{0}\".format(weeks)] = clearance_price\n",
    "        output_list[\"margin{0}\".format(weeks)] = clearance_price - cost_price\n",
    "        output_list[\"tp\".format(weeks)] = tp\n",
    "        output_list[\"cd{0}\".format(weeks)] = (clearance_price - self.current_price)*stock_level\n",
    "\n",
    "    cost_decision = (new_price - self.current_price)*stock_level\n",
    "    predicted_margin = new_price - cost_price\n",
    "    other_outputvars = dict(sku = sku, new_price = new_price, current_price = self.current_price, actual_price = self.actual_price,weeks_of_stock = weeks_of_stock ,current_velocity = current_velocity,current_margin = current_margin,predicted_throughput = predicted_throughput,predicted_margin = predicted_margin, stock_level = stock_level, name = self.name, department = self.department,cost_decision = cost_decision)\n",
    "    output_list.update(other_outputvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def price_point(self, group, current_price): ## What is the function supposed to do?\n",
    "        query = \"\"\"select * from price_architecture where sub_group = '{0}' order by price\"\"\".format(group)\n",
    "        price_points = pd.read_sql_query(query, self.engine)\n",
    "        prices = price_points['price']\n",
    "        try:\n",
    "            idx = np.where((np.abs(prices.tolist())-current_price)==((np.abs(prices.tolist())-current_price).argmin()))[0][0]\n",
    "        except:\n",
    "            return 0\n",
    "        idx = idx - 2\n",
    "        if idx < 0:\n",
    "            idx = 0\n",
    "        return price_points['price'][idx]\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " def write_to_db(self):\n",
    "    # removed try catch from sql and made some cosmetic changes.\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table1;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table2;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table1;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "\n",
    "    s3 = boto.connect_s3(AWSKEY, AWSSECRETKEY)\n",
    "    bucket = s3.get_bucket(BUCKET)\n",
    "    key_name =  '%s%s' % (PROJECT,int(time.time()))\n",
    "    print(key_name)\n",
    "    key = bucket.new_key(key_name)\n",
    "    key.set_contents_from_filename('%s.csv' %(PROJECT))\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS pricing_latest;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"create table pricing_latest (\\\n",
    "                     sku varchar,\\\n",
    "                     optimal_price float,\\\n",
    "                     week2_price float , \\\n",
    "                     week4_price float, \\\n",
    "                     week6_price float, \\\n",
    "                     suggested_price float,\\ \n",
    "                     week10_price float, \\\n",
    "                     current_price float, \\\n",
    "                     weeks_of_stock float, \\\n",
    "                     Current_weekly_velocity float, \\\n",
    "                     current_margin float, \\\n",
    "                     predicted_throughput float, \\\n",
    "                     predicted_margin float, \\\n",
    "                     stock_level float, \\\n",
    "                     name varchar, department varchar, \\\n",
    "                     week2_margin float, \\\n",
    "                     week4_margin float, \\\n",
    "                     week6_margin float, \\\n",
    "                     week8_margin float, \\\n",
    "                     week10_margin float, \\\n",
    "                     predicted_throughput_was_relevant_to_2_weeks float, \\\n",
    "                     predicted_throughput_was_relevant_to_4_weeks float, \\\n",
    "                     predicted_throughput_was_relevant_to_6_weeks float, \\\n",
    "                     predicted_throughput_was_relevant_to_8_weeks float, \\\n",
    "                     predicted_throughput_was_relevant_to_10_weeks float, \\\n",
    "                     cost_of_the_decision_was_relevant_to_2_weeks float, \\\n",
    "                     cost_of_the_decision_was_relevant_to_4_weeks float,\\\n",
    "                     cost_of_the_decision_was_relevant_to_6_weeks float, \\\n",
    "                     cost_of_the_decision_was_relevant_to_8_weeks float, \\\n",
    "                     cost_of_the_decision_was_relevant_to_10_weeks float, \\\n",
    "                     cost_of_the_decision float, \\\n",
    "                     parent_group varchar, \\\n",
    "                     season varchar, \\\n",
    "                     cost_price float,\\ \n",
    "                     published varchar, \\\n",
    "                     in_clearance varchar,\\ \n",
    "                     act_weeks_on_sale float,\\ \n",
    "                     original_standard_price float, \\\n",
    "                     current_standard_price float, \\\n",
    "                     current_percentage_achieved_margin float, \\\n",
    "                     suggested_price_percentage_margin float, \\\n",
    "                     suggestion varchar,price_2_Weeks_Percentage_Margin float, \\\n",
    "                     price_4_Weeks_Percentage_Margin float, \\\n",
    "                     price_6_Weeks_Percentage_Margin float, \\\n",
    "                     price_8_Weeks_Percentage_Margin float, \\\n",
    "                     price_10_Weeks_Percentage_Margin float, \\\n",
    "                     demand_Pounds_Last_7_Days float, \\\n",
    "                     next_7_days_weekly_velocity float\\\n",
    "                     demand_pounds_next_7_days float,\\\n",
    "                     next_7_days_margin float,stock_level_next_7_days float, \\\n",
    "                     currentdate timestamp default '2016-10-01 00:00:00.0');\")                                                                                                                                                                                                                                                                                            \n",
    "    self.conn.commit()\n",
    "    self.cur.execute(\"copy pricing_latest from 's3://%s/%s' CSV credentials 'aws_access_key_id=%s;aws_secret_access_key=%s';\" % (BUCKET,key_name, AWSKEY, AWSSECRETKEY))\n",
    "    self.conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## detached this from the write function\n",
    "pm = PricingModel()\n",
    "pm.cluster()\n",
    "pm.calculate_prices()\n",
    "pm.write_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
