{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4d5dc8232e4a>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-4d5dc8232e4a>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    \"\"\" Config \"\"\"\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import csv\n",
    "import boto\n",
    "import time\n",
    "import datetime as DT\n",
    "\n",
    "\"\"\" Config \"\"\"\n",
    "REDSHIFTUSER = \n",
    "REDSHIFTPWD = \n",
    "AWSKEY=\n",
    "AWSSECRETKEY=\n",
    "SCHEMA = \n",
    "DATABASE = \n",
    "HOST = \n",
    "BUCKET = \n",
    "PROJECT = \n",
    "KEYNAME = ''\n",
    "SKUSTRING = \"('AZZ00147','DZZ85020','DZZ85763','DZZ86970','DZZ87371','DZZ87486','DZZ87518','DZZ90639','DZZ92404');\"\n",
    "##SKUSTRING = \"('AZZ00147','DZZ85020','DZZ85763','DZZ86970','DZZ87371','DZZ87486','DZZ87518','DZZ90639','DZZ92404','DZZ92449','DZZ92926','DZZ93981','PZZ95782','PZZ95815','PZZ95886','PZZ96573','TZZ99870','TZZ99946','DZZ11112','DZZ86345','DZZ86407','DZZ87401','DZZ87827','DZZ89074','DZZ90335','DZZ91935','DZZ92830','DZZ94933','PZZ96012','PZZ96225','PZZ96299','PZZ96481','PZZ96611','AZZ01532','AZZ11496','DZZ85267','DZZ85878','DZZ86971','DZZ87381','DZZ91290','MZZ81507','MZZ96325','PZZ97215','AZZ01844','CZZ98889','DZZ85138','DZZ85883','DZZ87006','DZZ88977','DZZ89460','DZZ90673','DZZ91172','DZZ91263','MZZ81700','PZZ95726','PZZ95912','PZZ96000','PZZ97631','AZZ06437','AZZ19219','AZZ23121','DZZ87005','DZZ87360','DZZ87488','DZZ88274','DZZ97279','PZZ95727','PZZ96011','PZZ96293','AZZ00043','AZZ26617','AZZ35341','DZZ86246','DZZ86972','DZZ87252','DZZ89012','DZZ91562','DZZ92059','PZZ97267','PZZ97693','AZZ21063','AZZ22504','DZZ86245','DZZ86956','DZZ86962','DZZ87646','DZZ94234','DZZ94244','DZZ98575','MZZ83384','PZZ95870','PZZ96265','TZZ99935','AZZ00003','AZZ02218','AZZ04756','DZZ87372','DZZ87571','DZZ87647','DZZ87798','DZZ87898','DZZ89947','DZZ85267','DZZ87798','DZZ85763','DZZ87571','DZZ85138','DZZ94514','DZZ86407','DZZ90335','DZZ87486','DZZ89947');\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PricingModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Connect to the database and fetch the Product Details.\n",
    "        Two different libraries are used to connect to redshift. sqlalchemy is used for its integration with pandas\n",
    "        while psycopg2 is used to write the results to the db.\n",
    "        \"\"\"\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=HOST,\n",
    "            user=REDSHIFTUSER, \n",
    "            port=5439, \n",
    "            password=REDSHIFTPWD,\n",
    "            database=DATABASE)\n",
    "        self.cur = self.conn.cursor() # create a cursor for executing queries\n",
    "\n",
    "        engine_string = \"postgresql+psycopg2://%s:%s@%s:%d/%s\" % (REDSHIFTUSER, REDSHIFTPWD, HOST, 5439, DATABASE)\n",
    "        self.engine = create_engine(engine_string)\n",
    "\n",
    "        ##query_string = \"select * from boohoo.vw_product_details;\"\n",
    "        query_string = \"select * from vw_product_details where sku in %s;\" % (SKUSTRING)\n",
    "        ##query_string = \"select * from boohoo.vw_product_details where sku in ('AZZ00147','DZZ85020','DZZ85763','DZZ86970','DZZ87371','DZZ87486','DZZ87518','DZZ90639','DZZ92404','DZZ92449','DZZ92926');\"\n",
    "        self.df = pd.read_sql_query(query_string, self.engine)\n",
    "\n",
    "        ## Changed the queries to eliminate the trycatch statements, changed the froup by clause in string 3 and made cosmetics changes\n",
    "        q_string = \"\"\"DROP TABLE IF EXISTS temp_table;\n",
    "                        select split_part(orderlinesku, '-', 1) as sku , orderlineqty, orderdate, totalorderlinegrossvalue,orderlinepromotioncodes, orderlineid, bhline.orderid\n",
    "                        into temp_table\n",
    "                        from vw_order_line  bhline \n",
    "                        join vw_order_header  bhheader \n",
    "                        on bhline.orderid=bhheader.orderid;\"\"\"\n",
    "        \n",
    "        q_string2 = \"\"\"DROP TABLE IF EXISTS temp_table2;\n",
    "                        select * \n",
    "                        into temp_table2 \n",
    "                        from temp_table tt \n",
    "                        LEFT JOIN bh_returnheader ret \n",
    "                        ON ret.ordernumber = tt.orderid \n",
    "                        WHERE ret.ordernumber IS NULL;\"\"\"\n",
    "        q_string3 = \"\"\"DROP TABLE IF EXISTS temp_table3;\n",
    "                        select sku, sum(orderlineqty) number_orders, \n",
    "                        sum(totalorderlinegrossvalue) as total_cost,\n",
    "                        pgdate_part('week', orderdate) as week, \n",
    "                        pgdate_part('year', orderdate) as year \n",
    "                        into temp_table3\n",
    "                        from temp_table2\n",
    "                        group by sku,pgdate_part('week', orderdate),pgdate_part('year', orderdate);\"\"\"\n",
    "        \n",
    "        self.cur.execute(q_string)\n",
    "        print(\"q_string ran\")\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(q_string2)\n",
    "        print(\"q_string2 ran\")\n",
    "        self.conn.commit()\n",
    "        self.cur.execute(q_string3)\n",
    "        print(\"q_string3 ran\")\n",
    "        self.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster(self):\n",
    "    \"\"\" Perform clustering on the textual features describing the items of clothing.\n",
    "    \"\"\"\n",
    "    df = self.df.fillna('') #  change all nans to empty strings\n",
    "    # add all of the text features together\n",
    "    text_features = df['name'] + ' ' + df['product_group'] + ' ' + \\\n",
    "                    df['category'] + ' ' + df['department'] + ' ' + \\\n",
    "                    df['length'] + ' ' + df['origin'] + ' ' + \\\n",
    "                    df['style'] + ' ' + df['neckline'] + ' ' + \\\n",
    "                    df['trend'] + ' ' + df['heelshape'] + ' ' + \\\n",
    "                    df['toe'] + ' ' + df['sole'] + ' ' + \\\n",
    "                    df['heelheight'] + ' ' + df['wash'] + ' ' + \\\n",
    "                    df['enduse']\n",
    "\n",
    "    numerical_features = df[['cost_price', 'weight']]\n",
    "\n",
    "    tf = TfidfVectorizer(min_df=2)\n",
    "    self.X = tf.fit_transform(text_features)\n",
    "\n",
    "    self.nbrs = NearestNeighbors()\n",
    "    self.nbrs.fit(self.X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_prices(self):\n",
    "## Added comments, made the code readable. Also changed the order of variable creation for readability\n",
    "    # res_df_cl_all is only used to be passed as as an argument in the calculate_clearance_price function.\n",
    "    # Intialized it here in order to avoid multiple calls to the DB. Not related to the other res_df in the fn.\n",
    "    query_string1 = \"\"\"SELECT si.ItemID,split_part(Code, '-', 1) as sku,Code,Price,sip.PriceBandId,pb.Name, bi.quantityonhand, si.manufacturer\n",
    "                        FROM bh_StockItem si\n",
    "                        join bh_StockItemPrice sip on si.ItemID = sip.ItemID\n",
    "                        join bh_PriceBand pb on pb.PriceBandID = sip.PriceBandID\n",
    "                        join bh_dwh_stock_levels bi on si.code = bi.productid\n",
    "                        where pb.Name = 'Offer Price'\n",
    "                        and split_part(Code, '-', 1) in %s\"\"\" % (SKUSTRING) \n",
    "                     \n",
    "    res_df_cl_all = pd.read_sql_query(query_string1, self.engine) \n",
    "    print(\"Calc price Query 1 ran\")\n",
    "    query_string2 = \"\"\"select sku , orderlineqty, orderdate\n",
    "                        from temp_table\n",
    "                        where sku in %s\"\"\" % (SKUSTRING) \n",
    "    orders_by_date = pd.read_sql_query(query_string2, self.engine) \n",
    "    print(\"Calc price Query 2 ran\")\n",
    "    orders_by_date['orderdate'] = pd.to_datetime(orders_by_date['orderdate'])\n",
    "    \n",
    "    \n",
    "    with open(('%s.csv' %(PROJECT)), 'wb') as csvfile:\n",
    "        self.spamwriter = csv.writer(csvfile)\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            # [(k, v.sku) for k,v in self.df.iterrows() if v.sku == 'DZZ90335']\n",
    "            ## Initialize Values\n",
    "            published = self.df['published'][index]\n",
    "            in_clearance = self.df['in_clearance'][index]\n",
    "            act_weeks_on_sale = self.df['act_weeks_on_sale'][index]\n",
    "            original_standard_price = self.df['original_standard_price'][index]\n",
    "            current_standard_price = self.df['current_standard_price'][index]\n",
    "            cost_price = self.df['cost_price'][index]\n",
    "            sku = self.df['sku'][index]\n",
    "\n",
    "            self.name = self.df['name'][index]\n",
    "            self.department = self.df['product_group'][index]\n",
    "            self.current_price = current_standard_price ## Why are we doing this??\n",
    "\n",
    "            # Find Similar Skus\n",
    "            res = self.nbrs.kneighbors(self.X[index], return_distance=False)\n",
    "            print('Kmeans complete for the {0} time(s)'.format(index+1))\n",
    "            similar_skus = tuple([self.df.sku[a] for a in res[0]])\n",
    "\n",
    "            # Get orders of similar skus, summarized by week\n",
    "            query_string = \"select * from  temp_table3 where sku  in ('{0}','{1}','{2}','{3}','{4}')\".format(similar_skus[0], similar_skus[1], similar_skus[2], similar_skus[3], similar_skus[4]);\n",
    "            res_df = pd.read_sql_query(query_string, self.engine)               \n",
    "\n",
    "            total_weeks = len(res_df.groupby(['week', 'year']).count())\n",
    "            print((\"{0} Weeks of orders\").format(total_weeks))\n",
    "            # Calculate some values of Similar skus\n",
    "            try:\n",
    "                ideal_price = sum(res_df['total_cost'])/sum(res_df['number_orders'])\n",
    "            except:\n",
    "                ideal_price = self.df['cost_price'][index] + 10\n",
    "            ## merged the try except statements\n",
    "            try:\n",
    "                sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
    "                self.sim_items_sold_per_week = sum(res_df['number_orders'])/len(res_df)\n",
    "            except:\n",
    "                sim_items_sold_per_week = 10 \n",
    "                self.sim_items_sold_per_week = 10\n",
    "            \n",
    "            # Calculate values of actual sku\n",
    "            sp = res_df[res_df['sku'] == sku]\n",
    "            try:\n",
    "                items_sold_per_week = sum(sp['number_orders'])/len(sp)\n",
    "            except:\n",
    "                items_sold_per_week = sim_items_sold_per_week \n",
    "\n",
    "            #implement pricing logic\n",
    "            new_price = (ideal_price/sim_items_sold_per_week)*items_sold_per_week\n",
    "            weeks_on_sale = sp.count()['sku']\n",
    "\n",
    "            q_string = \"\"\"select totalorderlinegrossvalue from temp_table2 where orderlineid = (select max(orderlineid) from  temp_table where sku = '%s' and orderlinepromotioncodes = '')\"\"\" % sku \n",
    "            actual_df = pd.read_sql_query(q_string, self.engine)\n",
    "\n",
    "            try:\n",
    "                self.actual_price = actual_df['totalorderlinegrossvalue'].loc[0] \n",
    "            except:\n",
    "                self.actual_price = 0\n",
    "\n",
    "            try:\n",
    "                ss = sp.loc[0]\n",
    "                self.current_price = ss['total_cost']/ss['number_orders'] # practically, is this different from actual price?\n",
    "            except Exception as e: \n",
    "                self.current_price = self.actual_price\n",
    "            if self.current_price == 0:\n",
    "                self.current_price = current_standard_price \n",
    "\n",
    "            # Introduce some rule based checks\n",
    "            min_price = 0\n",
    "            if act_weeks_on_sale < 5:\n",
    "                min_price = price_point(self, self.df['product_group'][index].upper(), self.current_price)\n",
    "\n",
    "            if new_price < min_price:\n",
    "                new_price = min_price\n",
    "            if new_price > (original_standard_price + original_standard_price/10):\n",
    "                new_price = (original_standard_price + original_standard_price/10)\n",
    "            \n",
    "            print(sku)\n",
    "            res_df_cl = res_df_cl_all[res_df_cl_all['sku']==sku]    # to pass to the function below\n",
    "         \n",
    "            calculate_clearance_price(self,sku, res_df_cl, items_sold_per_week,orders_by_date, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price)\n",
    "            \n",
    "            ## Ideal price need not be passed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_clearance_price(self, sku, res_df_cl, items_sold_per_week,orders_by_date, new_price, ideal_price, sim_items_sold_per_week, cost_price, published, in_clearance, act_weeks_on_sale, original_standard_price, current_standard_price):\n",
    "    ## Ideal price is not used\n",
    "    try:\n",
    "        price = res_df_cl['price'].loc[0]\n",
    "    except: \n",
    "        price = 0\n",
    "    clearance_price = price\n",
    "    output_list = {}\n",
    "    predicted_throughput = self.sim_items_sold_per_week \n",
    "    stock_level = sum(res_df_cl['quantityonhand'])\n",
    "    try:\n",
    "        weeks_of_stock = stock_level/items_sold_per_week\n",
    "    except: \n",
    "        weeks_of_stock = 0\n",
    "    #old calc current_velocity = items_sold_per_week ## What's the purpose of this?? Can be removed\n",
    "    # Calculate the number of items sold in the last 7 days\n",
    "     try:\n",
    "        current_velocity = sum(orders_by_date[(orders_by_date.sku==sku) &\n",
    "                                                     (pd.to_datetime(orders_by_date['orderdate'])> (DT.date.today() - DT.timedelta(days = 7))) &\n",
    "                                                     (pd.to_datetime(orders_by_date['orderdate']) <= DT.date.today())].orderlineqty)\n",
    "    except:\n",
    "        current_velocity = 0\n",
    "        \n",
    "    current_margin = self.current_price - cost_price\n",
    "    for weeks in [2,4,6,8,10]:\n",
    "        if stock_level < (weeks*items_sold_per_week):\n",
    "            clearance_price = new_price\n",
    "            tp = predicted_throughput \n",
    "        else:\n",
    "            try:\n",
    "                clearance_price = new_price*(items_sold_per_week/(stock_level/weeks))\n",
    "                tp = (predicted_throughput - predicted_throughput * (items_sold_per_week/(stock_level/weeks))) + predicted_throughput \n",
    "            except: \n",
    "                clearance_price = new_price\n",
    "                tp = predicted_throughput \n",
    "\n",
    "        if clearance_price < cost_price:\n",
    "            clearance_price = cost_price\n",
    "        if new_price < price:\n",
    "            new_price = price                   \n",
    "        output_list[\"week{0}\".format(weeks)] = clearance_price\n",
    "        output_list[\"margin{0}\".format(weeks)] = clearance_price - cost_price\n",
    "        output_list[\"tp\".format(weeks)] = tp\n",
    "        output_list[\"cd{0}\".format(weeks)] = (clearance_price - self.current_price)*stock_level\n",
    "        #print((\"new price is {0}\").format(new_price))\n",
    "    cost_decision = (new_price - self.current_price)*stock_level\n",
    "    predicted_margin = new_price - cost_price\n",
    "    other_outputvars = dict(sku = sku, new_price = new_price, current_price = self.current_price, actual_price = self.actual_price,weeks_of_stock = weeks_of_stock ,current_velocity = current_velocity,current_margin = current_margin,predicted_throughput = predicted_throughput,predicted_margin = predicted_margin, stock_level = stock_level, name = self.name, department = self.department,cost_decision = cost_decision)\n",
    "    output_list.update(other_outputvars)\n",
    "    self.spamwriter.writerow([output_list])\n",
    "    #self.spamwriter.writerow([sku, new_price, week2, week4, week6, week8, week10, self.current_price,self.actual_price, weeks_of_stock , current_velocity, current_margin,predicted_throughput,predicted_margin, stock_level, self.name, self.department, margin2, margin4, margin6, margin8, margin10, tp2, tp4, tp6, tp8, tp10, cd2, cd4, cd6, cd8, cd10, cost_decision ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  def price_point(self, group, current_price): ## What is the function supposed to do?\n",
    "        query = \"\"\"select * from price_architecture where sub_group = '{0}' order by price\"\"\".format(group)\n",
    "        price_points = pd.read_sql_query(query, self.engine)\n",
    "        prices = price_points['price']\n",
    "        try:\n",
    "            idx = np.where((np.abs(prices.tolist())-current_price)==((np.abs(prices.tolist())-current_price).argmin()))[0][0]\n",
    "        except:\n",
    "            return 0\n",
    "        idx = idx - 2\n",
    "        if idx < 0:\n",
    "            idx = 0\n",
    "        return price_points['price'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def write_to_db(self):\n",
    "    # removed try catch from sql and made some cosmetic changes.\n",
    "    # default delimiter is tab, added correct delimiter and also added removequotes.\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table2;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS temp_table3;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "\n",
    "    s3 = boto.connect_s3(AWSKEY, AWSSECRETKEY)\n",
    "    bucket = s3.get_bucket(BUCKET)\n",
    "    key_name =  '%s-%s' % (PROJECT,int(time.time()))\n",
    "    print(key_name)\n",
    "    key = bucket.new_key(key_name)\n",
    "    key.set_contents_from_filename('%s.csv' %(PROJECT))\n",
    "\n",
    "    self.cur.execute(\"DROP TABLE IF EXISTS boohoo.boohoo_pricing;\")\n",
    "    self.conn.commit()\n",
    "\n",
    "    self.cur.execute(\"create table pricing (sku varchar,suggested_price float ,week2_price float , week4_price float, week6_price float, week8_price float, week10_price float, current_price float, actual_price float, weeks_of_stock float, Current_weekly_velocity float, current_margin float, predicted_throughput float, predicted_margin float, stock_level float, name varchar, department varchar, week2_margin float, week4_margin float, week6_margin float, week8_margin float, week10_margin float, predicted_throughput_was_relevant_to_2_weeks float, predicted_throughput_was_relevant_to_4_weeks float, predicted_throughput_was_relevant_to_6_weeks float, predicted_throughput_was_relevant_to_8_weeks float, predicted_throughput_was_relevant_to_10_weeks float);\")\n",
    "    self.conn.commit()\n",
    "    self.cur.execute(\"copy pricing from 's3://%s/%s' CSV credentials 'aws_access_key_id=%s;aws_secret_access_key=%s';\" % (BUCKET,key_name, AWSKEY, AWSSECRETKEY),removequotes,delimiter ',')\n",
    "    self.conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functional Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_string ran\n",
      "q_string2 ran\n",
      "q_string3 ran\n"
     ]
    }
   ],
   "source": [
    "pm = PricingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc price Query 1 ran\n",
      "Calc price Query 2 ran\n",
      "Kmeans complete for the 1 time(s)\n",
      "9 Weeks of orders\n",
      "AZZ00147\n",
      "Kmeans complete for the 2 time(s)\n",
      "17 Weeks of orders\n",
      "DZZ85763\n",
      "Kmeans complete for the 3 time(s)\n",
      "9 Weeks of orders\n",
      "DZZ86970\n",
      "Kmeans complete for the 4 time(s)\n",
      "17 Weeks of orders\n",
      "DZZ90639\n",
      "Kmeans complete for the 5 time(s)\n",
      "9 Weeks of orders\n",
      "DZZ87486\n",
      "Kmeans complete for the 6 time(s)\n",
      "8 Weeks of orders\n",
      "DZZ87518\n",
      "Kmeans complete for the 7 time(s)\n",
      "17 Weeks of orders\n",
      "DZZ92404\n",
      "Kmeans complete for the 8 time(s)\n",
      "17 Weeks of orders\n",
      "DZZ85020\n",
      "Kmeans complete for the 9 time(s)\n",
      "9 Weeks of orders\n",
      "DZZ87371\n"
     ]
    }
   ],
   "source": [
    "calculate_prices(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boohoo-pricing-1456495025\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Load into table 'boohoo_pricing' failed.  Check 'stl_load_errors' system table for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-49a4d8e875fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-776f42eb5d41>\u001b[0m in \u001b[0;36mwrite_to_db\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"create table boohoo.boohoo_pricing (sku varchar,suggested_price float ,week2_price float , week4_price float, week6_price float, week8_price float, week10_price float, current_price float, actual_price float, weeks_of_stock float, Current_weekly_velocity float, current_margin float, predicted_throughput float, predicted_margin float, stock_level float, name varchar, department varchar, week2_margin float, week4_margin float, week6_margin float, week8_margin float, week10_margin float, predicted_throughput_was_relevant_to_2_weeks float, predicted_throughput_was_relevant_to_4_weeks float, predicted_throughput_was_relevant_to_6_weeks float, predicted_throughput_was_relevant_to_8_weeks float, predicted_throughput_was_relevant_to_10_weeks float, cost_of_the_decision_was_relevant_to_2_weeks float, cost_of_the_decision_was_relevant_to_4_weeks float,cost_of_the_decision_was_relevant_to_6_weeks float, cost_of_the_decision_was_relevant_to_8_weeks float, cost_of_the_decision_was_relevant_to_10_weeks float, cost_of_the_decision float);\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"copy boohoo.boohoo_pricing from 's3://truedash-redshift/%s' CSV credentials 'aws_access_key_id=%s;aws_secret_access_key=%s';\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAWSKEY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAWSSECRETKEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Load into table 'boohoo_pricing' failed.  Check 'stl_load_errors' system table for details.\n"
     ]
    }
   ],
   "source": [
    "write_to_db(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
